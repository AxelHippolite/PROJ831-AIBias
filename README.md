# PROJ831-AIBias

![Python](https://img.shields.io/badge/Python-14354C?style=for-the-badge&logo=python&logoColor=white)
![R](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)

### Authors : BOUGHANMI Rami, HIPPOLITE Axel, RIBES MaÃ«l & WALLERAND Alex

This project addresses one of the most important challenges in the field of AI: learning bias. We will focus on two datasets: COMPAS and CITYSCAPES.  The datasets were respectively processed with the R Language and Python.

## Project objective

Our aim is to understand how bias can manifest itself in machine learning models and to explore ways to detect and mitigate it. We will follow the standard process of solving a machine learning problem, which includes data collection and pre-processing, exploratory data analysis, model selection and training, model performance evaluation, and finally model optimisation.

In this process, we will pay particular attention to the steps where biases can creep in, either through the data or through the algorithms themselves.

## Datasets Presentation

### COMPAS

COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a criminal recidivism risk assessment tool. It is used by US courts to assess an individual's risk of reoffending and to assist in making decisions about release, bail, and sentence length.

The COMPAS score is based on a set of 137 questions covering a wide range of topics, including criminal history, personal relationships, attitude towards crime, and other social and psychological factors.

### CITYSCAPES

Cityscapes is a large dataset of urban scene images from 50 different cities for use in computer vision research, particularly for semantic segmentation and scene recognition.

Each image in the dataset is accompanied by a precise annotation that indicates the object category of each pixel (e.g. car, building, pedestrian).